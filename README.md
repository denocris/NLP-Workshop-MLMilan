# Natural Language Processing Workshop - Machine Learning Milan

This workshop was supported by MLMilan. The idea is to show two NLP use cases using the most recent algorithms and libraries available (May 2020).

It is organized in two sessions:

In the first session, after a brief introduction to the Transformer library by HuggingFace and the NLP pipeline, Cristiano will talk about word-sense disambiguation and embedding visualization in the age of contextual embeddings (such as BERT). He will also touch some geometrical aspects hidden into transformer-based architectures. We will work on the Italian language and take advantage of the pre-trained checkpoints: Gilberto and Umberto. Here the [link to some helpful slide](https://docs.google.com/presentation/d/e/2PACX-1vQSCVJkfs5toV9UkFGx0JnEw6u9KJWe0HlwrooZ7I4FSbVF4LdAOhKjFrrjyHxDc1EflqMmGnvvo1-r/pub?start=false&loop=false&delayms=3000) to follow the first notebook.

During the second session, Andrea will introduce automatic summarization and focus on two different methods. He will build a version of TextRank to extract the most important sentences from a document. He will then examine Encoder-Decoder Transformer architectures and generate summaries using BART, a sequence-to-sequence denoising autoencoder Transformer model which can be seen as a generalization of its more famous predecessors such as BERT and GPT.


Cristiano owns a Ph.D. in theoretical physicist and he actively working in Deep Learning for 4 years. He is also a TEDx speaker (here is talk about AI, Humans and their future). Here is contacts

Andrea owns a Ph.D. in astrophysics... 

For any doutbs or questions feel free to contact us! 
