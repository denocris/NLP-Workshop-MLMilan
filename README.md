# Natural Language Processing Workshop - Machine Learning Milan

This workshop was supported by [Machine Learning Milan](https://twitter.com/ML_Milano), [IAML](https://twitter.com/iaml_it) and [AINDO](https://www.linkedin.com/company/aindo/). The aim is to show two NLP use cases using the most recent algorithms and libraries available (May 2020).

Authors: Andrea Gatto ([LinkedIn](https://www.linkedin.com/in/andrea-gatto/)) and Cristiano De Nobili ([LinkedIn](https://www.linkedin.com/in/cristiano-de-nobili/), [Twitter](https://twitter.com/denocris))

The workshop was recorded ([video link](https://www.youtube.com/watch?v=1vL3rn2ctuw&feature=youtu.be)) and it is organized in two sessions:

In the first session, after a brief introduction to the Transformers library by [HuggingFace](https://huggingface.co/) and the NLP pipeline, Cristiano talks about word-sense disambiguation and embedding visualization in the age of contextual embeddings (such as BERT). Also some geometrical aspects hidden into transformer-based architectures are touched. We focus on Italian language and take advantage of the pre-trained checkpoints: [Gilberto](https://huggingface.co/idb-ita/gilberto-uncased-from-camembert) and [Umberto](https://huggingface.co/Musixmatch/umberto-commoncrawl-cased-v1). Here's the [link to the slides](https://docs.google.com/presentation/d/e/2PACX-1vQSCVJkfs5toV9UkFGx0JnEw6u9KJWe0HlwrooZ7I4FSbVF4LdAOhKjFrrjyHxDc1EflqMmGnvvo1-r/pub?start=false&loop=false&delayms=3000) for this section.

During the second session, Andrea introduces automatic summarization and focuses on two different methods. In the first part we build our own version of TextRank to extract the most important sentences from a document. In the second we introduce encoder-decoder Transformer architectures and generate summaries using BART, a sequence-to-sequence denoising autoencoder Transformer part of the new wave of Transformer models for Natural Language Generation. [These are the slides](https://docs.google.com/presentation/d/13zb4KPoZyAQVqRWn1xcbHgxNHPg5Lgc5wD7QEbq0K68/present?token=AC4w5ViN4aKOqOx3j9TlaDRe82mCRFzoKQ%3A1590066722277&includes_info_params=1&eisi=CJa5mpGExekCFQZGJgodC70K7A#slide=id.p) for the second section.


Cristiano holds a Ph.D. in Theoretical Physics ([SISSA](https://twitter.com/Sissaschool)) and he has been actively working in Deep Learning for four years. In particular, he is now part of the Bixby project, Samsung's vocal assistant. He is also a TEDx speaker (here is talk about [AI, Humans and their future](https://youtu.be/8-hrmer9d_E)). Here his [contacts!](https://denocris.com/)

Andrea obtained his Ph.D. in Theoretical Astrophysics at the Max Planck Institute for Astrophysics in Munich. He worked as Software Developer and as Data Scientist in different business areas. Currently, he builds NLP models via Deep Learning for Bixby, Samsung's virtual assistant.

For any doubts or questions feel free to contact us! 
