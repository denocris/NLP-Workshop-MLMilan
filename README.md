# Natural Language Processing Workshop - Machine Learning Milan

This workshop was supported by [Machine Learning Milan](https://twitter.com/ML_Milano" target="_blank) and [IAML](https://twitter.com/iaml_it). The aim is to show two NLP use cases using the most recent algorithms and libraries available (May 2020).

[Machine Learning Milan](https://twitter.com/ML_Milano)

Autors: Andrea Gatto ([LinkedIn](https://www.linkedin.com/in/andrea-gatto/)) and Cristiano De Nobili ([LinkedIn](https://www.linkedin.com/in/cristiano-de-nobili/), [Twitter](https://twitter.com/denocris))

The workshop was recorded (here the video) and it is organized in two sessions:

In the first session, after a brief introduction to the Transformer library by [HuggingFace](https://huggingface.co/) and the NLP pipeline, Cristiano talks about word-sense disambiguation and embedding visualization in the age of contextual embeddings (such as BERT). Also some geometrical aspects hidden into transformer-based architectures are touched. Italian language is used and we take advantage of the pre-trained checkpoints: [Gilberto](https://huggingface.co/idb-ita/gilberto-uncased-from-camembert) and [Umberto](https://huggingface.co/Musixmatch/umberto-commoncrawl-cased-v1). Here the [link to some slide](https://docs.google.com/presentation/d/e/2PACX-1vQSCVJkfs5toV9UkFGx0JnEw6u9KJWe0HlwrooZ7I4FSbVF4LdAOhKjFrrjyHxDc1EflqMmGnvvo1-r/pub?start=false&loop=false&delayms=3000) that can be useful to follow the first notebook.

During the second session, Andrea introduces automatic summarization focusing on two different methods. A version of TextRank is built to extract the most important sentences from a document. An Encoder-Decoder Transformer architectures is examined and then we generate summaries using BART, a sequence-to-sequence denoising autoencoder Transformer model which can be seen as a generalization of its more famous predecessors such as BERT and GPT.


Cristiano owns a Ph.D. in theoretical physicist ([SISSA](https://twitter.com/Sissaschool)) and he has been actively working in deep learning for 4 years. He is also a TEDx speaker (here is talk about [AI, Humans and their future](https://youtu.be/8-hrmer9d_E)). Here is [contacts!](https://denocris.com/)

Andrea owns a Ph.D. in astrophysics... (TO DO)

For any doutbs or questions feel free to contact us! 
